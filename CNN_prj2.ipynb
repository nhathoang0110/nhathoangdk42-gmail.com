{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_prj2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhathoang0110/project2/blob/master/CNN_prj2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feXhhWMA-_Fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch  \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE8za8a0_Lmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "edd9590a-d7f6-4f44-e407-e68859bb1e30"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJQilbljIInf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "b2298833-b327-432d-e7c6-c86495e1807e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 22 09:01:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    34W / 250W |    903MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYLAYwQICKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from time import time\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "  with open(data_path, encoding = 'latin1') as f:\n",
        "    d_lines = f.read().splitlines()\n",
        "  data, labels, sentence_lengths = [], [], []\n",
        "  for line in d_lines:\n",
        "    features = line.split('<fff>')\n",
        "    label, doc_id, sentence_len = int(features[0]), int(features[1]), int(features[2])\n",
        "    vector = [int(ID) for ID in features[3].split()]\n",
        "    data.append(vector)\n",
        "    labels.append(label)\n",
        "    sentence_lengths.append(sentence_len)\n",
        "  return torch.tensor(data), torch.tensor(labels), torch.tensor(sentence_lengths)\n",
        "  \n",
        "train_data, train_labels, train_sentence_lengths = load_data(\n",
        "    data_path='/content/drive/My Drive/20news-train-encoded.txt'\n",
        ")\n",
        "test_data, test_labels, test_sentence_lengths = load_data(\n",
        "    data_path='/content/drive/My Drive/20news-test-encoded.txt'\n",
        ")\n",
        "with open('/content/drive/My Drive/vocab-raw.txt', encoding = 'latin1') as f:\n",
        "  vocab_size = len(f.read().splitlines())\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO-jN6o_Nvb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ae70e22c-0a09-4267-fd72-88e94bb03965"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "print(device)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_hEL_y_aQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_SIZE = 300\n",
        "MAX_DOC_LENGTH = 500\n",
        "NUM_CLASSES = 20\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "batch_size = 50\n",
        "train_set = TensorDataset(train_data, train_labels)\n",
        "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_size, batch_size):\n",
        "    super(CNN, self).__init__()\n",
        "    self._vocab_size = vocab_size\n",
        "    self._embedding_size = embedding_size\n",
        "    self._batch_size = batch_size\n",
        "    self.build()\n",
        "\n",
        "  def build(self):\n",
        "    self._embedding_layer = nn.Embedding(self._vocab_size+2, self._embedding_size)\n",
        "    self._convolutional_layer = nn.Sequential(\n",
        "        nn.Conv2d(1, 500, kernel_size=(5, self._embedding_size)),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self._full_connected_layer = nn.Linear(MAX_DOC_LENGTH, NUM_CLASSES)\n",
        "    self._loss_function = nn.CrossEntropyLoss()\n",
        "    self._dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "  def forward(self, inp):\n",
        "    embeddings = self._embedding_layer(inp).unsqueeze(1)\n",
        "    outputs = self._convolutional_layer(embeddings).squeeze(3)\n",
        "    outputs = F.max_pool1d(outputs, kernel_size=outputs.size(2)).squeeze(2)\n",
        "    outputs = self._dropout((outputs))\n",
        "    outputs = self._full_connected_layer(outputs)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "  # def fit(self, train_loader, max_epochs=50 ,learning_rate=0.01, threshold=1e-3):\n",
        "  #   # data_set = TensorDataset(train_data, train_labels)\n",
        "  #   # data_loader = DataLoader(data_set, batch_size = self._batch_size, shuffle = True)\n",
        "  #   opt = torch.optim.Adam(params = self.parameters(), lr = learning_rate)\n",
        "  #   self.train()\n",
        "  #   last_loss = 0\n",
        "  #   for epoch in range(max_epochs):\n",
        "  #     new_loss = 0\n",
        "  #     for data,labels in train_loader:\n",
        "  #       train = data.to(device)\n",
        "  #       labels = labels.to(device)\n",
        "  #       opt.zero_grad()\n",
        "  #       prediced = self.forward(data)\n",
        "  #       loss = self._loss_function(prediced, labels)\n",
        "  #       new_loss += loss\n",
        "  #       loss.backward()\n",
        "  #       opt.step()\n",
        "  #     new_loss = new_loss / len(train_loader)\n",
        "  #     print('epoch: {}, loss: {}'.format(epoch, new_loss))\n",
        "  #     print('test accuracy:',self.test(test_loader,device))\n",
        "  #     if abs(last_loss - new_loss) <= threshold:\n",
        "  #       return\n",
        "  #     last_loss=new_loss\n",
        "\n",
        "  # def test(self, test_loader):\n",
        "  #   # data_set = TensorDataset(test_data, test_labels)\n",
        "  #   # data_loader = DataLoader(data_set, batch_size = self._batch_size, shuffle = False)\n",
        "  #   num_true_predict = 0\n",
        "  #   self.eval()\n",
        "  #   for data, labels in test_loader:\n",
        "  #     data =data.to(device)\n",
        "  #     labels = labels.to(device)\n",
        "  #     predicted = torch.argmax(self.forward(data), dim = 1)\n",
        "  #     num_true_predict += sum((predicted == labels).float())\n",
        "  #   return num_true_predict*100./len(test_data)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o22pkaxI2lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "t=time()\n",
        "cnn = CNN(\n",
        "    vocab_size=vocab_size, \n",
        "    embedding_size=300,  \n",
        "    batch_size=32\n",
        ")\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VJ5s9p4JkgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "bf04c6f8-c62d-4e4d-f01d-329225ad519d"
      },
      "source": [
        "\n",
        "cnn.to(device)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (_embedding_layer): Embedding(18988, 300)\n",
              "  (_convolutional_layer): Sequential(\n",
              "    (0): Conv2d(1, 500, kernel_size=(5, 300), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (_full_connected_layer): Linear(in_features=500, out_features=20, bias=True)\n",
              "  (_loss_function): CrossEntropyLoss()\n",
              "  (_dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0vkp-XcT16H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.Adam(cnn.parameters(), lr = learning_rate)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV0uRZ3qSruC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf0f4510-fe80-4be8-8c99-6f432e1e8444"
      },
      "source": [
        "learning_rate=0.001\n",
        "max_epochs=50\n",
        "error = nn.CrossEntropyLoss()\n",
        "def test(model, test_data, test_labels):\n",
        "  data_set = TensorDataset(test_data, test_labels)\n",
        "  data_loader = DataLoader(data_set, batch_size = 32, shuffle = False)\n",
        "  num_true_predict = 0\n",
        "  model.eval()\n",
        "  for data, labels in data_loader:\n",
        "    data =data.to(device)\n",
        "    labels = labels.to(device)\n",
        "    predicted = torch.argmax(model(data), dim = 1)\n",
        "    num_true_predict += sum((predicted == labels).float())\n",
        "  return num_true_predict*100./len(test_data)\n",
        "cnn.train()\n",
        "last_loss = 0\n",
        "for epoch in range(max_epochs):\n",
        "  new_loss = 0\n",
        "  for data,labels in train_loader:\n",
        "    train = data.to(device)\n",
        "    labels = labels.to(device)\n",
        "    opt.zero_grad()\n",
        "    prediced = cnn(train)\n",
        "    loss = error(prediced, labels)\n",
        "    new_loss += loss\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "  new_loss = new_loss / len(train_loader)\n",
        "  print('epoch: {}, loss: {}'.format(epoch, new_loss))\n",
        "  print('test accuracy:',test(cnn,test_data, test_labels))\n",
        "  print('train accuracy:', test(cnn,train_data,train_labels))\n",
        "  # if abs(last_loss - new_loss) <= threshold:\n",
        "  #   return\n",
        "  last_loss=new_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 29.51390266418457\n",
            "test accuracy: tensor(71.6675, device='cuda:0')\n",
            "train accuracy: tensor(96.5088, device='cuda:0')\n",
            "epoch: 1, loss: 2.1171176433563232\n",
            "test accuracy: tensor(72.5305, device='cuda:0')\n",
            "train accuracy: tensor(97.3838, device='cuda:0')\n",
            "epoch: 2, loss: 0.5601410269737244\n",
            "test accuracy: tensor(72.8624, device='cuda:0')\n",
            "train accuracy: tensor(97.6136, device='cuda:0')\n",
            "epoch: 3, loss: 0.5515150427818298\n",
            "test accuracy: tensor(73.3271, device='cuda:0')\n",
            "train accuracy: tensor(97.7373, device='cuda:0')\n",
            "epoch: 4, loss: 0.1460321545600891\n",
            "test accuracy: tensor(73.3404, device='cuda:0')\n",
            "train accuracy: tensor(97.7550, device='cuda:0')\n",
            "epoch: 5, loss: 0.10092546045780182\n",
            "test accuracy: tensor(73.3404, device='cuda:0')\n",
            "train accuracy: tensor(97.7727, device='cuda:0')\n",
            "epoch: 6, loss: 0.08729109168052673\n",
            "test accuracy: tensor(73.3537, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 7, loss: 0.08204309642314911\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 8, loss: 0.08257915079593658\n",
            "test accuracy: tensor(73.3404, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 9, loss: 0.08512086421251297\n",
            "test accuracy: tensor(73.3404, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 10, loss: 0.08585815131664276\n",
            "test accuracy: tensor(73.3271, device='cuda:0')\n",
            "train accuracy: tensor(97.7727, device='cuda:0')\n",
            "epoch: 11, loss: 0.08613632619380951\n",
            "test accuracy: tensor(73.4068, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 12, loss: 0.08141573518514633\n",
            "test accuracy: tensor(73.5130, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 13, loss: 0.0875125601887703\n",
            "test accuracy: tensor(73.4599, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 14, loss: 0.07736563682556152\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 15, loss: 0.07619543373584747\n",
            "test accuracy: tensor(73.3404, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 16, loss: 0.0722317025065422\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 17, loss: 0.07075771689414978\n",
            "test accuracy: tensor(73.3537, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 18, loss: 0.07036352157592773\n",
            "test accuracy: tensor(73.3670, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 19, loss: 0.07112397998571396\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 20, loss: 0.07035212218761444\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7815, device='cuda:0')\n",
            "epoch: 21, loss: 0.07105129957199097\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7727, device='cuda:0')\n",
            "epoch: 22, loss: 0.07067572325468063\n",
            "test accuracy: tensor(73.3802, device='cuda:0')\n",
            "train accuracy: tensor(97.7727, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-29eb2cd74ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnew_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mnew_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXph2s1YI592",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "773e019d-3d39-423a-bb47-599d587a5d18"
      },
      "source": [
        "print('training time:',time()-t,'s')\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-fa6927adc88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training time:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-63738e9540c9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, max_epochs, learning_rate, threshold)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mprediced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mnew_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-63738e9540c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolutional_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM6MczSCSqtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsu9voA7J4TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}