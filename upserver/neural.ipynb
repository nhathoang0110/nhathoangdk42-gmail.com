{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def load_data(data_path, vocab_size):\n",
    "  with open(data_path, encoding = 'latin1') as f:\n",
    "    d_lines = f.read().splitlines()\n",
    "  data,labels = [],[]\n",
    "  for data_id, line in enumerate(d_lines):\n",
    "    vector = [0.0 for _ in range(vocab_size)]\n",
    "    features = line.split('<fff>')\n",
    "    label, doc_id = int(features[0]), int(features[1])\n",
    "    for token in features[2].split():\n",
    "      index, value = int(token.split(':')[0]), float(token.split(':')[1])\n",
    "      vector[index] = value\n",
    "    data.append(vector)\n",
    "    labels.append(label)\n",
    "  return torch.tensor(data), torch.tensor(labels)\n",
    "\n",
    "with open('/home/hoangntbn/Desktop/20192/project2/upserver/words_idf.txt', encoding = 'latin1') as f:\n",
    "  vocab_size = len(f.read().splitlines())\n",
    "X_train, Y_train = load_data(\n",
    "    '/home/hoangntbn/Desktop/20192/project2/upserver/train_tf_idf_vector.txt', vocab_size)\n",
    "X_test,Y_test = load_data(\n",
    "    '/home/hoangntbn/Desktop/20192/project2/upserver/test_tf_idf_vector.txt', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NeuronNetwork(torch.nn.Module):\n",
    "  def __init__(self, vocab_size, hidden_size, num_classes):\n",
    "    super().__init__()\n",
    "    self._vocab_size = vocab_size\n",
    "    self._hidden_size = hidden_size\n",
    "    self._num_classes = num_classes\n",
    "\n",
    "  def build_graph(self):\n",
    "    self._hidden_layer = torch.nn.Linear(self._vocab_size, self._hidden_size)\n",
    "    self._output_layer = torch.nn.Linear(self._hidden_size, self._num_classes)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = torch.sigmoid(self._hidden_layer(x))\n",
    "    x = F.softmax(self._output_layer(x), dim = 1)\n",
    "    return x\n",
    "\n",
    "  def fit(self, X_train, Y_train, batch_size, max_epochs=50 ,learning_rate=1e-2, threshold=1e-3):\n",
    "    self.build_graph()\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "    data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "    opt = torch.optim.Adam(params = self.parameters(), lr = learning_rate)\n",
    "    last_loss = 0\n",
    "    for epoch in range(max_epochs):\n",
    "      new_loss = 0\n",
    "      for data,labels in data_loader:\n",
    "        self.zero_grad()\n",
    "       \n",
    "   \n",
    "        loss = F.cross_entropy(prediced, labels)\n",
    "        new_loss += loss\n",
    "       \n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "      new_loss = new_loss / len(data_loader)\n",
    "      print('iter: {}, loss: {}'.format(epoch, new_loss))\n",
    "      if abs(last_loss - new_loss) <= threshold:\n",
    "        return\n",
    "      last_loss=new_loss\n",
    "\n",
    "  def predict(self, X):\n",
    "    return torch.argmax(self.forward(X), dim = 1)\n",
    "\n",
    "  def compute_accuracy(self,predicted,expected):\n",
    "    return (predicted == expected).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t=time()\n",
    "NN = NeuronNetwork(\n",
    "    vocab_size = vocab_size,\n",
    "    hidden_size = 30,\n",
    "    num_classes = 20\n",
    "    )\n",
    "NN.fit(\n",
    "    X_train = X_train,\n",
    "    Y_train = Y_train,\n",
    "    batch_size = 32,\n",
    "    max_epochs = 50,\n",
    "    learning_rate = 1e-2,\n",
    "    threshold = 1e-3\n",
    "    )\n",
    "print('training time:',time()-t,'s')\n",
    "predicted = NN.predict(X_train)\n",
    "print('train accuracy:', NN.compute_accuracy(predicted, Y_train))\n",
    "predicted = NN.predict(X_test)\n",
    "print('test accuracy:', NN.compute_accuracy(predicted, Y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}