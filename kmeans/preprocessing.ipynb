{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer  \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docfile(file1):\n",
    "    with open(file1,\"rb\") as f:\n",
    "        contents = f.read()\n",
    "        contents = contents.decode('utf-8','ignore')\n",
    "    f.close()\n",
    "\n",
    "    arrays=contents.split()\n",
    "\n",
    "    # arrays=word_tokenize(contents)\n",
    "\n",
    "    #loai bo ky tu dac biet va so\n",
    "    for i in range(0,len(arrays)):\n",
    "        arrays[i]= arrays[i].lower()\n",
    "        arrays[i]= re.sub(r'[^a-z]', '', arrays[i])\n",
    "    \n",
    "    #loai bo stopword\n",
    "    array1=[]\n",
    "    for word in arrays:\n",
    "        if(word) not in (stopwords.words('english')):\n",
    "            array1.append(word)\n",
    "\n",
    "    # steamming\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    array2=[]\n",
    "    for word in array1:\n",
    "        if(len(word)<10 and len(word)>2):\n",
    "            array2.append(stemmer.stem(word))\n",
    "    \n",
    "    \n",
    "    tf = np.unique(array2, return_counts = True)[1].tolist()         #bo tu lap\n",
    "    value = np.unique(array2, return_counts = True)[0].tolist()\n",
    "    str=' '.join(value)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train=\"/home/hoangntbn/Desktop/20192/project2/20news-bydate/20news-bydate-train\"\n",
    "path_test=\"/home/hoangntbn/Desktop/20192/project2/20news-bydate/20news-bydate-test\"\n",
    "FJoin = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(path):\n",
    "    contents = \"\"\n",
    "    labels = \"\"\n",
    "\n",
    "    dirs = [FJoin(path, f) for f in os.listdir(path)]\n",
    "\n",
    "    for i in range(0,len(dirs)): \n",
    "        d = dirs[i]  \n",
    "        files = [FJoin(d, f) for f in os.listdir(d)]\n",
    "        for j in range(0,len(files)):\n",
    "            s = docfile(files[j])\n",
    "            s = str(i) + \"<###>\" +  s + \"\\n\"\n",
    "            contents = contents + s\n",
    "            labels = labels + str(i) + \"\\n\"\n",
    "\n",
    "    return contents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_train, labels_train = solve(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"train.txt\", \"w+\")\n",
    "file.write(contents_train)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"labels_train.txt\", \"w+\")\n",
    "file.write(labels_train)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_test, labels_test = solve(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"test.txt\", \"w+\")\n",
    "file.write(contents_test)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"labels_test.txt\", \"w+\")\n",
    "file.write(labels_test)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = contents_train + contents_test\n",
    "file = open(\"all.txt\", \"w+\")\n",
    "file.write(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_train + labels_test\n",
    "file = open(\"labels.txt\", \"w+\")\n",
    "file.write(labels)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}